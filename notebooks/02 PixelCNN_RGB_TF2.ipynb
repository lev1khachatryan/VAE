{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Pixel CNN for RGB Images</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The original ***Pixel Recurrent Neural Networks*** paper](https://arxiv.org/abs/1601.06759)\n",
    "\n",
    "[The original ***Conditional Image Generation with PixelCNN Decoders*** paper](https://arxiv.org/abs/1606.05328)\n",
    "\n",
    "[PixelCNN](http://sergeiturukin.com/2017/02/22/pixelcnn.html)\n",
    "\n",
    "[Gated PixelCNN](http://sergeiturukin.com/2017/02/24/gated-pixelcnn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv2D(tfkl.Layer):\n",
    "    def __init__(self, type, n_colors, filters, kernel_size, strides=1,\n",
    "                 padding='SAME', name='masked_conv'):\n",
    "        super(MaskedConv2D, self).__init__(name=name)\n",
    "\n",
    "        if type not in {'A', 'B'}:\n",
    "            raise ValueError(\"MaskedConv2D type should be in (A, B), \"\n",
    "                            f\"got {type}\")\n",
    "\n",
    "        self.type = type\n",
    "        self.n_colors = n_colors\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, H, W, in_ch = input_shape\n",
    "        out_ch = self.filters\n",
    "\n",
    "        if isinstance(self.kernel_size, tuple):\n",
    "            k_y, k_x = self.kernel_size\n",
    "        else:\n",
    "            k_y = self.kernel_size\n",
    "            k_x = self.kernel_size\n",
    "\n",
    "        # Instantiate variables\n",
    "        initializer = tfk.initializers.GlorotUniform()\n",
    "        self.kernel = tf.Variable(\n",
    "            initializer((k_y, k_x, in_ch, out_ch), dtype=tf.float32),\n",
    "            trainable=True,\n",
    "            aggregation=tf.VariableAggregation.MEAN,\n",
    "            name='kernel'\n",
    "        )\n",
    "\n",
    "        self.bias = tf.Variable(\n",
    "            initializer((1, 1, 1, out_ch), dtype=tf.float32),\n",
    "            trainable=True,\n",
    "            aggregation=tf.VariableAggregation.MEAN,\n",
    "            name='bias'\n",
    "        )\n",
    "\n",
    "        # Create the mask\n",
    "        mid_x, mid_y = k_x // 2, k_y // 2\n",
    "\n",
    "        # Number of pixels to keep per row depending on type\n",
    "        pixels_per_row_A = [k_x] * mid_y + [mid_x] + [0] * (k_y - mid_y - 1)\n",
    "        pixels_per_row_B = [k_x] * mid_y + [mid_x + 1] + [0] * (k_y - mid_y - 1)\n",
    "        pixels_per_row_A = tf.expand_dims(pixels_per_row_A, axis=1)\n",
    "        pixels_per_row_B = tf.expand_dims(pixels_per_row_B, axis=1)\n",
    "\n",
    "        # Flat 2D masks\n",
    "        lines = tf.expand_dims(tf.range(k_x), axis=0)\n",
    "        mask_A = tf.less(lines, pixels_per_row_A)\n",
    "        mask_B = tf.less(lines, pixels_per_row_B)\n",
    "\n",
    "        # Expand dims\n",
    "        in_ch_per_color = in_ch // self.n_colors\n",
    "        out_ch_per_color = out_ch // self.n_colors\n",
    "        mask_A = tf.tile(\n",
    "            mask_A[:, :, None, None],\n",
    "            [1, 1, in_ch_per_color, out_ch_per_color]\n",
    "        )\n",
    "        mask_B = tf.tile(\n",
    "            mask_B[:, :, None, None],\n",
    "            [1, 1, in_ch_per_color, out_ch_per_color]\n",
    "        )\n",
    "        mask_0 = tf.zeros_like(mask_A, dtype=tf.bool)\n",
    "\n",
    "        # feature map group : (R, G, B) -> (R, G, B)\n",
    "        mask_colors = []\n",
    "        if self.type == 'B':\n",
    "            # mask patterns : (B, O, O), (B, B, 0), (B, B, B)\n",
    "            mask_colors = []\n",
    "            for i in range(self.n_colors):\n",
    "                masks = [mask_B] * (i+1) + [mask_0] * (self.n_colors-i-1)\n",
    "                mask_colors.append(tf.concat(masks, axis=2))\n",
    "        else:  # Apply A or B depending on the color\n",
    "            # mask patterns : (A, O, O), (B, A, 0), (B, B, A)\n",
    "            for i in range(self.n_colors):\n",
    "                masks = [mask_B] * i + [mask_A] + [mask_0] * (self.n_colors-i-1)\n",
    "                mask_colors.append(tf.concat(masks, axis=2))\n",
    "\n",
    "        self.mask = tf.concat(mask_colors, axis=3)\n",
    "        self.mask = tf.cast(self.mask, tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        h = tf.nn.conv2d(\n",
    "            input=x,\n",
    "            filters=self.kernel * self.mask,\n",
    "            strides=self.strides,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        return h + self.bias\n",
    "\n",
    "class ResidualBlock(tfkl.Layer):\n",
    "    def __init__(self, n_colors, **kwargs):\n",
    "        super(ResidualBlock, self).__init__(**kwargs)\n",
    "        self.n_colors = n_colors\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input shape (batch_size, height, width, channels)\n",
    "        hidden_dim = input_shape[-1]\n",
    "\n",
    "        self.conv1 = MaskedConv2D(\n",
    "            type='B',\n",
    "            n_colors=self.n_colors,\n",
    "            filters=hidden_dim // 2,\n",
    "            kernel_size=1,\n",
    "            name='conv1x1_1'\n",
    "        )\n",
    "\n",
    "        self.conv2 = MaskedConv2D(\n",
    "            type='B',\n",
    "            n_colors=self.n_colors,\n",
    "            filters=hidden_dim // 2,\n",
    "            kernel_size=3,\n",
    "            padding='SAME',\n",
    "            name='conv3x3'\n",
    "        )\n",
    "\n",
    "        self.conv3 = MaskedConv2D(\n",
    "            type='B',\n",
    "            n_colors=self.n_colors,\n",
    "            filters=hidden_dim,\n",
    "            kernel_size=1,\n",
    "            name='conv1x1_2'\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        # x shape (batch_size, height, width, channels)\n",
    "        h = self.conv1(tf.nn.relu(x))\n",
    "        h = self.conv2(tf.nn.relu(h))\n",
    "        h = self.conv3(tf.nn.relu(h))\n",
    "        return x + h\n",
    "\n",
    "class PixelCNN(tfk.Model):\n",
    "    def __init__(self, hidden_dim, n_res=5, n_output=256, **kwargs):\n",
    "        super(PixelCNN, self).__init__(**kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_res = n_res\n",
    "        self.n_output = 256  # number of possible pixel values\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Save image_shape for generation\n",
    "        self.image_shape = input_shape[1:]\n",
    "\n",
    "        n_colors = input_shape[-1]\n",
    "        self.n_colors = n_colors\n",
    "\n",
    "        self.conv_a = MaskedConv2D(\n",
    "            type='A',\n",
    "            n_colors=n_colors,\n",
    "            kernel_size=7,\n",
    "            filters=2 * n_colors * self.hidden_dim,\n",
    "            padding='SAME',\n",
    "            name='conv_a'\n",
    "        )\n",
    "\n",
    "        self.res_blocks = [\n",
    "            ResidualBlock(n_colors=n_colors, name=f'res_block{i}')\n",
    "            for i in range(self.n_res)\n",
    "        ]\n",
    "\n",
    "        self.conv_b_1 = MaskedConv2D(\n",
    "            type='B',\n",
    "            n_colors=n_colors,\n",
    "            kernel_size=1,\n",
    "            filters=n_colors * self.n_output,\n",
    "            name='conv_b_1'\n",
    "        )\n",
    "\n",
    "        self.conv_b_2 = MaskedConv2D(\n",
    "            type='B',\n",
    "            n_colors=n_colors,\n",
    "            kernel_size=1,\n",
    "            filters=n_colors * self.n_output,\n",
    "            name='conv_b_2'\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        h = self.conv_a(x)\n",
    "\n",
    "        for res_block in self.res_blocks:\n",
    "            h = res_block(h)\n",
    "\n",
    "        h = self.conv_b_1(tf.nn.relu(h))\n",
    "        h = self.conv_b_2(tf.nn.relu(h))\n",
    "\n",
    "        # Format output\n",
    "        h = tf.split(h, num_or_size_splits=self.n_colors, axis=-1)\n",
    "        outputs = tf.stack(h, axis=3)  # (batch_size, height, width, n_colors, n_output)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def sample(self, n):\n",
    "        # Sample n images from PixelCNN\n",
    "        height, width, channels = self.image_shape\n",
    "        n_pixels = height * width * channels\n",
    "\n",
    "        logits = tf.ones((n_pixels, self.n_output))\n",
    "        flat_samples = tf.cast(tf.random.categorical(logits, n), tf.float32)\n",
    "        samples = tf.reshape(flat_samples, (n, height, width, channels))\n",
    "\n",
    "        # Sample each pixel sequentially and feed it back\n",
    "        for pos in tqdm(range(n_pixels), desc=\"Sampling PixelCNN\"):\n",
    "            c = pos % channels\n",
    "            h = (pos // channels) // height\n",
    "            w = (pos // channels) % height\n",
    "            logits = self(samples)[:, h, w, c]\n",
    "            updates = tf.squeeze(tf.cast(tf.random.categorical(logits, 1), tf.float32))\n",
    "            indices = tf.constant([[i, h, w, c] for i in range(n)])\n",
    "            samples = tf.tensor_scatter_nd_update(samples, indices, updates)\n",
    "\n",
    "        return samples\n",
    "\n",
    "def bits_per_dim_loss(y_true, y_pred):\n",
    "    \"\"\"Return the bits per dim value of the predicted distribution.\"\"\"\n",
    "    B, H, W, C = y_true.shape\n",
    "    num_pixels = float(H * W * C)\n",
    "    log_probs = tf.math.log_softmax(y_pred, axis=-1)\n",
    "    log_probs = tf.gather(log_probs, tf.cast(y_true, tf.int32), axis=-1, batch_dims=4)\n",
    "    nll = - tf.reduce_sum(log_probs, axis=[1, 2, 3])\n",
    "    bits_per_dim = nll / num_pixels / tf.math.log(2.)\n",
    "    return bits_per_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "class PlotSamplesCallback(tfk.callbacks.Callback):\n",
    "    \"\"\"Plot `nex` reconstructed image to tensorboard.\"\"\"\n",
    "    def __init__(self, logdir: str, nex: int=4):\n",
    "        super(PlotSamplesCallback, self).__init__()\n",
    "        logdir = os.path.join(logdir, 'samples')\n",
    "        self.file_writer = tf.summary.create_file_writer(logdir=logdir)\n",
    "        self.nex = nex\n",
    "\n",
    "    def plot_img(self, image):\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "        image = tf.cast(image, tf.int32)\n",
    "\n",
    "        if image.shape[-1] == 1:\n",
    "            image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "        ax.imshow(image, vmin=0, vmax=255, cmap=plt.cm.Greys)\n",
    "        ax.axis('off')\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        images = self.model.sample(self.nex)\n",
    "\n",
    "        imgs = []\n",
    "        for i in range(self.nex):\n",
    "            fig = self.plot_img(images[i])\n",
    "            imgs.append(plot_to_image(fig))\n",
    "\n",
    "        imgs = tf.concat(imgs, axis=0)\n",
    "        with self.file_writer.as_default():\n",
    "            tf.summary.image(\n",
    "                name='Samples',\n",
    "                data=imgs,\n",
    "                step=epoch,\n",
    "                max_outputs=self.nex\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    epochs = 10\n",
    "    batch = 64\n",
    "    buffer = 1024 # Buffer size for shuffling\n",
    "    dataset = 'mnist' # cifar10 or mnist\n",
    "    learning_rate = 0.001\n",
    "    lr_decay = 0.999995\n",
    "    hidden_dim = 64 # Hidden dimension per channel\n",
    "    n_res = 4 # Number of res blocks\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "EPOCHS = args.epochs\n",
    "BATCH_SIZE = args.batch\n",
    "BUFFER_SIZE = args.buffer  # for shuffling\n",
    "\n",
    "# Load dataset\n",
    "dataset, info = tfds.load(args.dataset, with_info=True)\n",
    "train_ds, test_ds = dataset['train'], dataset['test']\n",
    "\n",
    "def prepare(element):\n",
    "    image = element['image']\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # The image is not normalized\n",
    "    return image\n",
    "\n",
    "# PixelCNN training requires target = input\n",
    "def duplicate(element):\n",
    "    return element, element\n",
    "\n",
    "train_ds = (train_ds.shuffle(BUFFER_SIZE)\n",
    "                    .batch(BATCH_SIZE)\n",
    "                    .map(prepare, num_parallel_calls=AUTOTUNE)\n",
    "                    .map(duplicate)\n",
    "                    .prefetch(AUTOTUNE))\n",
    "\n",
    "test_ds = (test_ds.batch(BATCH_SIZE)\n",
    "                   .map(prepare, num_parallel_calls=AUTOTUNE)\n",
    "                   .map(duplicate)\n",
    "                   .prefetch(AUTOTUNE))\n",
    "\n",
    "# Define model\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    model = PixelCNN(\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        n_res=args.n_res\n",
    "    )\n",
    "    model.compile(optimizer='adam', loss=bits_per_dim_loss)\n",
    "\n",
    "# Learning rate scheduler\n",
    "steps_per_epochs = info.splits['train'].num_examples // args.batch\n",
    "decay_per_epoch = args.lr_decay ** steps_per_epochs\n",
    "schedule = tfk.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=args.learning_rate,\n",
    "    decay_rate=decay_per_epoch,\n",
    "    decay_steps=1\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "time = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "log_dir = os.path.join('.', 'logs', 'pixelcnn', time)\n",
    "tensorboard_clbk = tfk.callbacks.TensorBoard(log_dir=log_dir)\n",
    "sample_clbk = PlotSamplesCallback(logdir=log_dir)\n",
    "scheduler_clbk = tfk.callbacks.LearningRateScheduler(schedule)\n",
    "callbacks = [tensorboard_clbk, sample_clbk, scheduler_clbk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2",
   "language": "python",
   "name": "tf_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
